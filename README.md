# SAM 2: å›¾åƒå’Œè§†é¢‘ä¸­çš„é€šç”¨åˆ†å‰²æ¨¡å‹

**[Meta AI, FAIR](https://ai.meta.com/research/)**

[Nikhila Ravi](https://nikhilaravi.com/), [Valentin Gabeur](https://gabeur.github.io/), [Yuan-Ting Hu](https://scholar.google.com/citations?user=E8DVVYQAAAAJ&hl=en), [Ronghang Hu](https://ronghanghu.com/), [Chaitanya Ryali](https://scholar.google.com/citations?user=4LWx24UAAAAJ&hl=en), [Tengyu Ma](https://scholar.google.com/citations?user=VeTSl0wAAAAJ&hl=en), [Haitham Khedr](https://hkhedr.com/), [Roman RÃ¤dle](https://scholar.google.de/citations?user=Tpt57v0AAAAJ&hl=en), [Chloe Rolland](https://scholar.google.com/citations?hl=fr&user=n-SnMhoAAAAJ), [Laura Gustafson](https://scholar.google.com/citations?user=c8IpF9gAAAAJ&hl=en), [Eric Mintun](https://ericmintun.github.io/), [Junting Pan](https://junting.github.io/), [Kalyan Vasudev Alwala](https://scholar.google.co.in/citations?user=m34oaWEAAAAJ&hl=en), [Nicolas Carion](https://www.nicolascarion.com/), [Chao-Yuan Wu](https://chaoyuan.org/), [Ross Girshick](https://www.rossgirshick.info/), [Piotr DollÃ¡r](https://pdollar.github.io/), [Christoph Feichtenhofer](https://feichtenhofer.github.io/)

[[`è®ºæ–‡`](https://ai.meta.com/research/publications/sam-2-segment-anything-in-images-and-videos/)] [[`é¡¹ç›®ä¸»é¡µ`](https://ai.meta.com/sam2)] [[`åœ¨çº¿æ¼”ç¤º`](https://sam2.metademolab.com/)] [[`æ•°æ®é›†`](https://ai.meta.com/datasets/segment-anything-video)] [[`åšå®¢`](https://ai.meta.com/blog/segment-anything-2)] [[`å¼•ç”¨`](#å¼•ç”¨-sam-2)]

![SAM 2 æ¶æ„](assets/model_diagram.png?raw=true)

**Segment Anything Model 2 (SAM 2)** æ˜¯ä¸€ä¸ªåŸºç¡€æ¨¡å‹ï¼Œç”¨äºè§£å†³å›¾åƒå’Œè§†é¢‘ä¸­çš„å¯æç¤ºè§†è§‰åˆ†å‰²é—®é¢˜ã€‚æˆ‘ä»¬å°†SAMæ‰©å±•åˆ°è§†é¢‘é¢†åŸŸï¼Œå°†å›¾åƒè§†ä¸ºå•å¸§è§†é¢‘ã€‚æ¨¡å‹è®¾è®¡é‡‡ç”¨ç®€å•çš„transformeræ¶æ„ï¼Œå…·æœ‰æµå¼å†…å­˜ï¼Œæ”¯æŒå®æ—¶è§†é¢‘å¤„ç†ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ¨¡å‹åœ¨ç¯æ•°æ®å¼•æ“ï¼Œé€šè¿‡ç”¨æˆ·äº¤äº’æ”¹è¿›æ¨¡å‹å’Œæ•°æ®ï¼Œæ”¶é›†äº†[**SA-Væ•°æ®é›†**](https://ai.meta.com/datasets/segment-anything-video)ï¼Œè¿™æ˜¯è¿„ä»Šä¸ºæ­¢æœ€å¤§çš„è§†é¢‘åˆ†å‰²æ•°æ®é›†ã€‚åœ¨æˆ‘ä»¬çš„æ•°æ®ä¸Šè®­ç»ƒçš„SAM 2åœ¨å¹¿æ³›çš„ä»»åŠ¡å’Œè§†è§‰é¢†åŸŸéƒ½è¡¨ç°å‡ºè‰²ã€‚

![SA-V æ•°æ®é›†](assets/sa_v_dataset.jpg?raw=true)

## æœ€æ–°æ›´æ–°

**2024å¹´12æœˆ11æ—¥ -- å®Œæ•´æ¨¡å‹ç¼–è¯‘å®ç°é‡å¤§VOSåŠ é€Ÿå’Œæ–°çš„`SAM2VideoPredictor`ä»¥æ›´å¥½åœ°å¤„ç†å¤šå¯¹è±¡è·Ÿè¸ª**

- æˆ‘ä»¬ç°åœ¨æ”¯æŒæ•´ä¸ªSAM 2æ¨¡å‹çš„`torch.compile`ï¼Œå¯ä»¥é€šè¿‡åœ¨`build_sam2_video_predictor`ä¸­è®¾ç½®`vos_optimized=True`æ¥å¼€å¯ï¼Œè¿™å°†æ˜¾è‘—æå‡VOSæ¨ç†é€Ÿåº¦ã€‚
- æˆ‘ä»¬æ›´æ–°äº†`SAM2VideoPredictor`çš„å®ç°ï¼Œæ”¯æŒç‹¬ç«‹çš„æ¯å¯¹è±¡æ¨ç†ï¼Œå…è®¸æˆ‘ä»¬æ”¾å®½å¤šå¯¹è±¡è·Ÿè¸ªçš„æç¤ºå‡è®¾ï¼Œå¹¶åœ¨è·Ÿè¸ªå¼€å§‹åæ·»åŠ æ–°å¯¹è±¡ã€‚
- è¯¦æƒ…è¯·å‚è§[`RELEASE_NOTES.md`](RELEASE_NOTES.md)ã€‚

**2024å¹´9æœˆ30æ—¥ -- SAM 2.1 å¼€å‘è€…å¥—ä»¶å‘å¸ƒï¼ˆæ–°æ£€æŸ¥ç‚¹ã€è®­ç»ƒä»£ç ã€Webæ¼”ç¤ºï¼‰**

- å‘å¸ƒäº†ä¸€å¥—æ”¹è¿›çš„æ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆæ ‡è®°ä¸º**SAM 2.1**ï¼‰ã€‚è¯¦æƒ…è¯·å‚è§[æ¨¡å‹æè¿°](#æ¨¡å‹æè¿°)ã€‚
  * è¦ä½¿ç”¨æ–°çš„SAM 2.1æ£€æŸ¥ç‚¹ï¼Œæ‚¨éœ€è¦ä»æ­¤ä»“åº“è·å–æœ€æ–°çš„æ¨¡å‹ä»£ç ã€‚å¦‚æœæ‚¨å·²å®‰è£…æ­¤ä»“åº“çš„æ—©æœŸç‰ˆæœ¬ï¼Œè¯·å…ˆé€šè¿‡`pip uninstall SAM-2`å¸è½½ä¹‹å‰çš„ç‰ˆæœ¬ï¼Œä»æ­¤ä»“åº“æ‹‰å–æœ€æ–°ä»£ç ï¼ˆä½¿ç”¨`git pull`ï¼‰ï¼Œç„¶åæŒ‰ç…§ä¸‹é¢çš„[å®‰è£…](#å®‰è£…)è¯´æ˜é‡æ–°å®‰è£…ã€‚
- è®­ç»ƒï¼ˆå’Œå¾®è°ƒï¼‰ä»£ç å·²å‘å¸ƒã€‚è¯·å‚è§[`training/README.md`](training/README.md)äº†è§£å¦‚ä½•å¼€å§‹ã€‚
- SAM 2 Webæ¼”ç¤ºçš„å‰ç«¯+åç«¯ä»£ç å·²å‘å¸ƒã€‚è¯¦æƒ…è¯·å‚è§[`demo/README.md`](demo/README.md)ã€‚

## ğŸš€ å¿«é€Ÿå¯åŠ¨

### å¯åŠ¨æˆ‘ä»¬çš„SAM2 OCRç¿»è¯‘ç³»ç»Ÿ

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 2. å¯åŠ¨Webåº”ç”¨
python run.py

# 3. è®¿é—®Webç•Œé¢
# æœ¬åœ°è®¿é—®: http://localhost:5000
# ç½‘ç»œè®¿é—®: http://[æ‚¨çš„IP]:5000
```

### ç›´æ¥å¯åŠ¨Flaskåº”ç”¨

```bash
# ç›´æ¥è¿è¡Œapp.py
python app.py

# è®¿é—®åœ°å€: http://localhost:5000
```

### å¯åŠ¨åŸæœ‰SAM2é¡¹ç›®

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/facebookresearch/sam2.git && cd sam2

# 2. å®‰è£…ä¾èµ–
pip install -e .
pip install -e ".[notebooks]"

# 3. å®‰è£…OCRä¾èµ–
cd OCR && pip install -r requirements.txt && cd ..

# 4. ä¸‹è½½æ¨¡å‹æ£€æŸ¥ç‚¹
cd checkpoints && ./download_ckpts.sh && cd ..

# 5. å¯åŠ¨Webæ¼”ç¤ºç•Œé¢
cd demo && docker-compose up
```

### åˆ†æ­¥å¯åŠ¨

#### å¯åŠ¨SAM 2æ ¸å¿ƒåŠŸèƒ½
```bash
# å®‰è£…SAM 2
pip install -e .

# ä¸‹è½½æ¨¡å‹
cd checkpoints && ./download_ckpts.sh && cd ..

# è¿è¡Œç¤ºä¾‹
jupyter notebook notebooks/image_predictor_example.ipynb
```

#### å¯åŠ¨OCRåŠŸèƒ½
```bash
# å®‰è£…OCRä¾èµ–
cd OCR && pip install -r requirements.txt && cd ..

# è¿è¡ŒOCR
python OCR/ocr_processor.py --image path/to/image.jpg
```

#### å¯åŠ¨Webæ¼”ç¤º
```bash
# å¯åŠ¨Webç•Œé¢
cd demo && docker-compose up

# è®¿é—® http://localhost:3000
```

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®ç»“åˆäº†SAM 2ï¼ˆé€šç”¨åˆ†å‰²æ¨¡å‹2ï¼‰å’ŒOCRï¼ˆå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼‰åŠŸèƒ½ï¼Œæä¾›äº†ä¸€ä¸ªå…¨é¢çš„è®¡ç®—æœºè§†è§‰è§£å†³æ–¹æ¡ˆã€‚ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š

- **å›¾åƒå’Œè§†é¢‘åˆ†å‰²**ï¼šä½¿ç”¨SAM 2è¿›è¡Œå¯¹è±¡åˆ†å‰²ã€äº¤äº’å¼åˆ†å‰²ã€è‡ªåŠ¨æ©ç ç”Ÿæˆ
- **OCRæ–‡æœ¬æå–**ï¼šä»å›¾åƒä¸­æå–æ–‡æœ¬ï¼Œæ”¯æŒå¤šè¯­è¨€è¯†åˆ«
- **Webæ¼”ç¤ºç•Œé¢**ï¼šæä¾›ç”¨æˆ·å‹å¥½çš„äº¤äº’å¼å·¥å…·
- **è®­ç»ƒå’Œå¾®è°ƒ**ï¼šæ”¯æŒè‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒå’Œæ¨¡å‹ä¼˜åŒ–

## å®‰è£…

SAM 2éœ€è¦å…ˆå®‰è£…æ‰èƒ½ä½¿ç”¨ã€‚ä»£ç è¦æ±‚`python>=3.10`ï¼Œä»¥åŠ`torch>=2.5.1`å’Œ`torchvision>=0.20.1`ã€‚è¯·æŒ‰ç…§[è¿™é‡Œ](https://pytorch.org/get-started/locally/)çš„è¯´æ˜å®‰è£…PyTorchå’ŒTorchVisionä¾èµ–ã€‚æ‚¨å¯ä»¥åœ¨GPUæœºå™¨ä¸Šä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…SAM 2ï¼š

```bash
git clone https://github.com/facebookresearch/sam2.git && cd sam2

pip install -e .
```

å¦‚æœæ‚¨åœ¨Windowsä¸Šå®‰è£…ï¼Œå¼ºçƒˆå»ºè®®ä½¿ç”¨[Windows Subsystem for Linux (WSL)](https://learn.microsoft.com/en-us/windows/wsl/install)å’ŒUbuntuã€‚

è¦ä½¿ç”¨SAM 2é¢„æµ‹å™¨å¹¶è¿è¡Œç¤ºä¾‹notebookï¼Œéœ€è¦å®‰è£…`jupyter`å’Œ`matplotlib`ï¼š

```bash
pip install -e ".[notebooks]"
```

æ³¨æ„ï¼š
1. å»ºè®®é€šè¿‡[Anaconda](https://www.anaconda.com/)ä¸ºæ­¤å®‰è£…åˆ›å»ºæ–°çš„Pythonç¯å¢ƒï¼Œå¹¶é€šè¿‡`pip`å®‰è£…PyTorch 2.5.1ï¼ˆæˆ–æ›´é«˜ç‰ˆæœ¬ï¼‰ï¼ŒæŒ‰ç…§https://pytorch.org/çš„è¯´æ˜ã€‚å¦‚æœæ‚¨å½“å‰ç¯å¢ƒä¸­çš„PyTorchç‰ˆæœ¬ä½äº2.5.1ï¼Œä¸Šè¿°å®‰è£…å‘½ä»¤å°†å°è¯•ä½¿ç”¨`pip`å°†å…¶å‡çº§åˆ°æœ€æ–°çš„PyTorchç‰ˆæœ¬ã€‚
2. ä¸Šè¿°æ­¥éª¤éœ€è¦ä½¿ç”¨`nvcc`ç¼–è¯‘å™¨ç¼–è¯‘è‡ªå®šä¹‰CUDAå†…æ ¸ã€‚å¦‚æœæ‚¨çš„æœºå™¨ä¸Šè¿˜æ²¡æœ‰ï¼Œè¯·å®‰è£…ä¸PyTorch CUDAç‰ˆæœ¬åŒ¹é…çš„[CUDAå·¥å…·åŒ…](https://developer.nvidia.com/cuda-toolkit-archive)ã€‚
3. å¦‚æœåœ¨å®‰è£…è¿‡ç¨‹ä¸­çœ‹åˆ°ç±»ä¼¼`Failed to build the SAM 2 CUDA extension`çš„æ¶ˆæ¯ï¼Œæ‚¨å¯ä»¥å¿½ç•¥å®ƒï¼Œä»ç„¶å¯ä»¥ä½¿ç”¨SAM 2ï¼ˆæŸäº›åå¤„ç†åŠŸèƒ½å¯èƒ½æœ‰é™ï¼Œä½†åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä¸ä¼šå½±å“ç»“æœï¼‰ã€‚

æœ‰å…³æ½œåœ¨é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆçš„å¸¸è§é—®é¢˜ï¼Œè¯·å‚è§[`INSTALL.md`](./INSTALL.md)ã€‚

## å¿«é€Ÿå¼€å§‹

### ä¸‹è½½æ¨¡å‹æ£€æŸ¥ç‚¹

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸‹è½½æ¨¡å‹æ£€æŸ¥ç‚¹ã€‚å¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤ä¸‹è½½æ‰€æœ‰æ¨¡å‹æ£€æŸ¥ç‚¹ï¼š

```bash
cd checkpoints && \
./download_ckpts.sh && \
cd ..
```

æˆ–å•ç‹¬ä¸‹è½½ï¼š

- [sam2.1_hiera_tiny.pt](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_tiny.pt)
- [sam2.1_hiera_small.pt](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_small.pt)
- [sam2.1_hiera_base_plus.pt](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_base_plus.pt)
- [sam2.1_hiera_large.pt](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt)

ï¼ˆæ³¨æ„ï¼šè¿™äº›æ˜¯æ ‡è®°ä¸ºSAM 2.1çš„æ”¹è¿›æ£€æŸ¥ç‚¹ï¼›è¯¦æƒ…è¯·å‚è§[æ¨¡å‹æè¿°](#æ¨¡å‹æè¿°ï¼‰ã€‚ï¼‰

ç„¶åï¼ŒSAM 2å¯ä»¥ç”¨äºå›¾åƒå’Œè§†é¢‘é¢„æµ‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

### å›¾åƒé¢„æµ‹

SAM 2å…·æœ‰[SAM](https://github.com/facebookresearch/segment-anything)åœ¨é™æ€å›¾åƒä¸Šçš„æ‰€æœ‰åŠŸèƒ½ï¼Œæˆ‘ä»¬æä¾›ä¸SAMéå¸¸ç›¸ä¼¼çš„å›¾åƒé¢„æµ‹APIï¼Œç”¨äºå›¾åƒç”¨ä¾‹ã€‚`SAM2ImagePredictor`ç±»ä¸ºå›¾åƒæç¤ºæä¾›äº†ç®€å•çš„æ¥å£ã€‚

```python
import torch
from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor

checkpoint = "./checkpoints/sam2.1_hiera_large.pt"
model_cfg = "configs/sam2.1/sam2.1_hiera_l.yaml"
predictor = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))

with torch.inference_mode(), torch.autocast("cuda", dtype=torch.bfloat16):
    predictor.set_image(<æ‚¨çš„å›¾åƒ>)
    masks, _, _ = predictor.predict(<è¾“å…¥æç¤º>)
```

æœ‰å…³é™æ€å›¾åƒç”¨ä¾‹çš„ç¤ºä¾‹ï¼Œè¯·å‚è€ƒ[image_predictor_example.ipynb](./notebooks/image_predictor_example.ipynb)ï¼ˆä¹Ÿå¯åœ¨Colabä¸­æŸ¥çœ‹[è¿™é‡Œ](https://colab.research.google.com/github/facebookresearch/sam2/blob/main/notebooks/image_predictor_example.ipynb)ï¼‰ã€‚

SAM 2è¿˜æ”¯æŒå›¾åƒçš„è‡ªåŠ¨æ©ç ç”Ÿæˆï¼Œå°±åƒSAMä¸€æ ·ã€‚æœ‰å…³å›¾åƒè‡ªåŠ¨æ©ç ç”Ÿæˆçš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[automatic_mask_generator_example.ipynb](./notebooks/automatic_mask_generator_example.ipynb)ï¼ˆä¹Ÿå¯åœ¨Colabä¸­æŸ¥çœ‹[è¿™é‡Œ](https://colab.research.google.com/github/facebookresearch/sam2/blob/main/notebooks/automatic_mask_generator_example.ipynb)ï¼‰ã€‚

### è§†é¢‘é¢„æµ‹

å¯¹äºè§†é¢‘ä¸­çš„å¯æç¤ºåˆ†å‰²å’Œè·Ÿè¸ªï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªè§†é¢‘é¢„æµ‹å™¨ï¼Œå…·æœ‰APIï¼Œä¾‹å¦‚æ·»åŠ æç¤ºå¹¶åœ¨æ•´ä¸ªè§†é¢‘ä¸­ä¼ æ’­æ©ç ã€‚SAM 2æ”¯æŒè§†é¢‘ä¸Šçš„å¤šå¯¹è±¡æ¨ç†ï¼Œå¹¶ä½¿ç”¨æ¨ç†çŠ¶æ€æ¥è·Ÿè¸ªæ¯ä¸ªè§†é¢‘ä¸­çš„äº¤äº’ã€‚

```python
import torch
from sam2.build_sam import build_sam2_video_predictor

checkpoint = "./checkpoints/sam2.1_hiera_large.pt"
model_cfg = "configs/sam2.1/sam2.1_hiera_l.yaml"
predictor = build_sam2_video_predictor(model_cfg, checkpoint)

with torch.inference_mode(), torch.autocast("cuda", dtype=torch.bfloat16):
    state = predictor.init_state(<æ‚¨çš„è§†é¢‘>)

    # æ·»åŠ æ–°æç¤ºå¹¶ç«‹å³åœ¨åŒä¸€å¸§ä¸Šè·å¾—è¾“å‡º
    frame_idx, object_ids, masks = predictor.add_new_points_or_box(state, <æ‚¨çš„æç¤º>):

    # ä¼ æ’­æç¤ºä»¥åœ¨æ•´ä¸ªè§†é¢‘ä¸­è·å¾—æ©ç 
    for frame_idx, object_ids, masks in predictor.propagate_in_video(state):
        ...
```

æœ‰å…³å¦‚ä½•æ·»åŠ ç‚¹å‡»æˆ–æ¡†æç¤ºã€è¿›è¡Œç»†åŒ–ä»¥åŠåœ¨è§†é¢‘ä¸­è·Ÿè¸ªå¤šä¸ªå¯¹è±¡çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è€ƒ[video_predictor_example.ipynb](./notebooks/video_predictor_example.ipynb)ä¸­çš„ç¤ºä¾‹ï¼ˆä¹Ÿå¯åœ¨Colabä¸­æŸ¥çœ‹[è¿™é‡Œ](https://colab.research.google.com/github/facebookresearch/sam2/blob/main/notebooks/video_predictor_example.ipynb)ï¼‰ã€‚

## ä»ğŸ¤— Hugging FaceåŠ è½½

æˆ–è€…ï¼Œæ¨¡å‹ä¹Ÿå¯ä»¥ä»[Hugging Face](https://huggingface.co/models?search=facebook/sam2)åŠ è½½ï¼ˆéœ€è¦`pip install huggingface_hub`ï¼‰ã€‚

å¯¹äºå›¾åƒé¢„æµ‹ï¼š

```python
import torch
from sam2.sam2_image_predictor import SAM2ImagePredictor

predictor = SAM2ImagePredictor.from_pretrained("facebook/sam2-hiera-large")

with torch.inference_mode(), torch.autocast("cuda", dtype=torch.bfloat16):
    predictor.set_image(<æ‚¨çš„å›¾åƒ>)
    masks, _, _ = predictor.predict(<è¾“å…¥æç¤º>)
```

å¯¹äºè§†é¢‘é¢„æµ‹ï¼š

```python
import torch
from sam2.sam2_video_predictor import SAM2VideoPredictor

predictor = SAM2VideoPredictor.from_pretrained("facebook/sam2-hiera-large")

with torch.inference_mode(), torch.autocast("cuda", dtype=torch.bfloat16):
    state = predictor.init_state(<æ‚¨çš„è§†é¢‘>)

    # æ·»åŠ æ–°æç¤ºå¹¶ç«‹å³åœ¨åŒä¸€å¸§ä¸Šè·å¾—è¾“å‡º
    frame_idx, object_ids, masks = predictor.add_new_points_or_box(state, <æ‚¨çš„æç¤º>):

    # ä¼ æ’­æç¤ºä»¥åœ¨æ•´ä¸ªè§†é¢‘ä¸­è·å¾—æ©ç 
    for frame_idx, object_ids, masks in predictor.propagate_in_video(state):
        ...
```

## OCRåŠŸèƒ½

æœ¬é¡¹ç›®è¿˜åŒ…æ‹¬OCRï¼ˆå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼‰åŠŸèƒ½ï¼Œç”¨äºä»å›¾åƒä¸­æå–æ–‡æœ¬ã€‚OCRæ¨¡å—æä¾›äº†å¤„ç†å›¾åƒå’Œæå–æ–‡æœ¬å†…å®¹çš„å·¥å…·ã€‚

### OCRç‰¹æ€§

- **æ–‡æœ¬è¯†åˆ«**ï¼šä»å„ç§å›¾åƒæ ¼å¼ä¸­æå–æ–‡æœ¬
- **å›¾åƒå¤„ç†**ï¼šè‡ªåŠ¨å›¾åƒå¤§å°è°ƒæ•´å’Œä¼˜åŒ–
- **å¤šè¯­è¨€æ”¯æŒ**ï¼šæ”¯æŒåŒ…æ‹¬ä¸­æ–‡å’Œè‹±æ–‡åœ¨å†…çš„å¤šç§è¯­è¨€
- **è¾“å‡ºæ ¼å¼**ï¼šç”ŸæˆåŒ…å«æ–‡æœ¬å’Œåæ ‡çš„ç»“æ„åŒ–JSONè¾“å‡º

### OCRå®‰è£…

å®‰è£…OCRä¾èµ–ï¼š

```bash
cd OCR
pip install -r requirements.txt
```

### OCRä½¿ç”¨æ–¹æ³•

#### åŸºæœ¬OCRå¤„ç†

```python
from OCR.ocr_processor import OCRProcessor

# åˆå§‹åŒ–OCRå¤„ç†å™¨
processor = OCRProcessor()

# å¤„ç†å›¾åƒ
result = processor.process_image("path/to/image.jpg")

# è·å–æå–çš„æ–‡æœ¬
print(result.text)
print(result.confidence)
```

#### å›¾åƒå¤§å°è°ƒæ•´

OCRæ¨¡å—åŒ…å«ä¸€ä¸ªPNGå›¾åƒå¤§å°è°ƒæ•´è„šæœ¬ï¼Œå¯ä»¥è‡ªåŠ¨è°ƒæ•´å›¾åƒå¤§å°ï¼š

```bash
# åŸºæœ¬ç”¨æ³•
python OCR/resize_png.py input.png

# æŒ‡å®šè¾“å‡ºæ–‡ä»¶
python OCR/resize_png.py input.png -o output.png

# æŒ‡å®šæœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
python OCR/resize_png.py input.png -s 2.0

# å®Œæ•´ç¤ºä¾‹
python OCR/resize_png.py input.png -o output.png -s 3.5
```

æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[OCR README](OCR/README.md)ã€‚

## é¡¹ç›®ä½¿ç”¨æŒ‡å—

æœ¬é¡¹ç›®ç»“åˆäº†SAM 2ï¼ˆé€šç”¨åˆ†å‰²æ¨¡å‹2ï¼‰å’ŒOCRåŠŸèƒ½ï¼Œæä¾›äº†ä¸€ä¸ªå…¨é¢çš„è®¡ç®—æœºè§†è§‰è§£å†³æ–¹æ¡ˆã€‚ä»¥ä¸‹æ˜¯ä¸åŒç»„ä»¶çš„ä½¿ç”¨æ–¹æ³•ï¼š

### 1. å›¾åƒå’Œè§†é¢‘åˆ†å‰²ï¼ˆSAM 2ï¼‰

**ä½¿ç”¨åœºæ™¯ï¼š**
- å›¾åƒå’Œè§†é¢‘ä¸­çš„å¯¹è±¡åˆ†å‰²
- äº¤äº’å¼åˆ†å‰²æç¤º
- è‡ªåŠ¨æ©ç ç”Ÿæˆ
- è§†é¢‘ä¸­çš„å¤šå¯¹è±¡è·Ÿè¸ª

**å¿«é€Ÿå¼€å§‹ï¼š**
```bash
# å®‰è£…ä¾èµ–
pip install -e .

# ä¸‹è½½æ¨¡å‹æ£€æŸ¥ç‚¹
cd checkpoints && ./download_ckpts.sh && cd ..

# è¿è¡Œç¤ºä¾‹
jupyter notebook notebooks/image_predictor_example.ipynb
jupyter notebook notebooks/video_predictor_example.ipynb
```

### 2. OCRæ–‡æœ¬æå–

**ä½¿ç”¨åœºæ™¯ï¼š**
- ä»å›¾åƒä¸­æå–æ–‡æœ¬
- å¤„ç†æ–‡æ¡£å’Œæˆªå›¾
- å¤šè¯­è¨€æ–‡æœ¬è¯†åˆ«
- ç”Ÿæˆç»“æ„åŒ–æ–‡æœ¬æ•°æ®

**å¿«é€Ÿå¼€å§‹ï¼š**
```bash
# å®‰è£…OCRä¾èµ–
cd OCR && pip install -r requirements.txt && cd ..

# åœ¨å›¾åƒä¸Šè¿è¡ŒOCR
python OCR/ocr_processor.py --image path/to/image.jpg
```

### 3. Webæ¼”ç¤ºç•Œé¢

**ä½¿ç”¨åœºæ™¯ï¼š**
- SAM 2çš„äº¤äº’å¼Webç•Œé¢
- å®æ—¶è§†é¢‘å¤„ç†
- ç”¨æˆ·å‹å¥½çš„åˆ†å‰²å·¥å…·

**å¿«é€Ÿå¼€å§‹ï¼š**
```bash
# å¯åŠ¨Webæ¼”ç¤º
cd demo
docker-compose up
# æˆ–æŒ‰ç…§demo/README.mdè¿›è¡Œè¯¦ç»†è®¾ç½®
```

### 4. è®­ç»ƒå’Œå¾®è°ƒ

**ä½¿ç”¨åœºæ™¯ï¼š**
- è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒ
- ç‰¹å®šé¢†åŸŸçš„æ¨¡å‹å¾®è°ƒ
- æ€§èƒ½ä¼˜åŒ–

**å¿«é€Ÿå¼€å§‹ï¼š**
```bash
# æŒ‰ç…§è®­ç»ƒæŒ‡å—
cd training
# æŸ¥çœ‹training/README.mdäº†è§£è¯¦ç»†è¯´æ˜
```

### 5. å®Œæ•´å·¥ä½œæµç¤ºä¾‹

ä»¥ä¸‹æ˜¯ç»“åˆå¤šä¸ªåŠŸèƒ½çš„å…¸å‹å·¥ä½œæµï¼š

```python
# 1. ä½¿ç”¨SAM 2åœ¨å›¾åƒä¸­åˆ†å‰²å¯¹è±¡
from sam2.sam2_image_predictor import SAM2ImagePredictor
predictor = SAM2ImagePredictor.from_pretrained("facebook/sam2-hiera-large")
masks, _, _ = predictor.predict(prompts)

# 2. ä½¿ç”¨OCRä»åŒä¸€å›¾åƒä¸­æå–æ–‡æœ¬
from OCR.ocr_processor import OCRProcessor
ocr = OCRProcessor()
text_result = ocr.process_image("image.jpg")

# 3. ç»“åˆç»“æœè¿›è¡Œç»¼åˆåˆ†æ
print(f"æ‰¾åˆ°{len(masks)}ä¸ªå¯¹è±¡å’Œ{len(text_result.text)}ä¸ªæ–‡æœ¬å…ƒç´ ")
```

## æ¨¡å‹æè¿°

### SAM 2.1 æ£€æŸ¥ç‚¹

ä¸‹è¡¨æ˜¾ç¤ºäº†2024å¹´9æœˆ29æ—¥å‘å¸ƒçš„æ”¹è¿›SAM 2.1æ£€æŸ¥ç‚¹ã€‚
|      **æ¨¡å‹**       | **å¤§å° (M)** |    **é€Ÿåº¦ (FPS)**     | **SA-Væµ‹è¯• (J&F)** | **MOSEéªŒè¯ (J&F)** | **LVOS v2 (J&F)** |
| :------------------: | :----------: | :--------------------: | :-----------------: | :----------------: | :---------------: |
|   sam2.1_hiera_tiny <br /> ([é…ç½®](sam2/configs/sam2.1/sam2.1_hiera_t.yaml), [æ£€æŸ¥ç‚¹](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_tiny.pt))    |     38.9     |          91.2          |        76.5         |        71.8        |       77.3        |
|   sam2.1_hiera_small <br /> ([é…ç½®](sam2/configs/sam2.1/sam2.1_hiera_s.yaml), [æ£€æŸ¥ç‚¹](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_small.pt))   |      46      |          84.8          |        76.6         |        73.5        |       78.3        |
| sam2.1_hiera_base_plus <br /> ([é…ç½®](sam2/configs/sam2.1/sam2.1_hiera_b+.yaml), [æ£€æŸ¥ç‚¹](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_base_plus.pt)) |     80.8     |        64.1          |        78.2         |        73.7        |       78.2        |
|   sam2.1_hiera_large <br /> ([é…ç½®](sam2/configs/sam2.1/sam2.1_hiera_l.yaml), [æ£€æŸ¥ç‚¹](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt))   |    224.4     |          39.5          |        79.5         |        74.6        |       80.6        |

### SAM 2 æ£€æŸ¥ç‚¹

2024å¹´7æœˆ29æ—¥å‘å¸ƒçš„å…ˆå‰SAM 2æ£€æŸ¥ç‚¹å¦‚ä¸‹ï¼š

|      **æ¨¡å‹**       | **å¤§å° (M)** |    **é€Ÿåº¦ (FPS)**     | **SA-Væµ‹è¯• (J&F)** | **MOSEéªŒè¯ (J&F)** | **LVOS v2 (J&F)** |
| :------------------: | :----------: | :--------------------: | :-----------------: | :----------------: | :---------------: |
|   sam2_hiera_tiny <br /> ([é…ç½®](sam2/configs/sam2/sam2_hiera_t.yaml), [æ£€æŸ¥ç‚¹](https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt))   |     38.9     |          91.5          |        75.0         |        70.9        |       75.3        |
|   sam2_hiera_small <br /> ([é…ç½®](sam2/configs/sam2/sam2_hiera_s.yaml), [æ£€æŸ¥ç‚¹](https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt))   |      46      |          85.6          |        74.9         |        71.5        |       76.4        |
| sam2_hiera_base_plus <br /> ([é…ç½®](sam2/configs/sam2/sam2_hiera_b+.yaml), [æ£€æŸ¥ç‚¹](https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt)) |     80.8     |     64.8    |        74.7         |        72.8        |       75.8        |
|   sam2_hiera_large <br /> ([é…ç½®](sam2/configs/sam2/sam2_hiera_l.yaml), [æ£€æŸ¥ç‚¹](https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt))   |    224.4     | 39.7 |        76.0         |        74.6        |       79.8        |

é€Ÿåº¦åœ¨A100ä¸Šæµ‹é‡ï¼Œä½¿ç”¨`torch 2.5.1, cuda 12.4`ã€‚æœ‰å…³åŸºå‡†æµ‹è¯•çš„ç¤ºä¾‹ï¼Œè¯·å‚è§`benchmark.py`ï¼ˆç¼–è¯‘æ‰€æœ‰æ¨¡å‹ç»„ä»¶ï¼‰ã€‚ä»…ç¼–è¯‘å›¾åƒç¼–ç å™¨å¯ä»¥æ›´çµæ´»ï¼Œä¹Ÿå¯ä»¥æä¾›ï¼ˆè¾ƒå°çš„ï¼‰åŠ é€Ÿï¼ˆåœ¨é…ç½®ä¸­è®¾ç½®`compile_image_encoder: True`ï¼‰ã€‚

## é¡¹ç›®ç»“æ„

```
sam2/
â”œâ”€â”€ sam2/                    # æ ¸å¿ƒSAM 2å®ç°
â”œâ”€â”€ OCR/                     # OCRåŠŸèƒ½
â”œâ”€â”€ demo/                    # Webæ¼”ç¤ºç•Œé¢
â”œâ”€â”€ training/                # è®­ç»ƒå’Œå¾®è°ƒä»£ç 
â”œâ”€â”€ notebooks/               # ç¤ºä¾‹notebook
â”œâ”€â”€ checkpoints/             # æ¨¡å‹æ£€æŸ¥ç‚¹
â””â”€â”€ tools/                   # å®ç”¨è„šæœ¬
```

## ç³»ç»Ÿè¦æ±‚

- **Python**: 3.10+
- **PyTorch**: 2.5.1+
- **CUDA**: 11.8+ï¼ˆç”¨äºGPUåŠ é€Ÿï¼‰
- **å†…å­˜**: 8GB+ RAMï¼ˆæ¨è16GB+ï¼‰
- **å­˜å‚¨**: 10GB+ç”¨äºæ¨¡å‹å’Œæ•°æ®é›†

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **GPUåŠ é€Ÿ**: ä½¿ç”¨CUDAå…¼å®¹GPUè·å¾—æœ€ä½³æ€§èƒ½
2. **æ¨¡å‹é€‰æ‹©**: æ ¹æ®æ‚¨çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å‹å¤§å°ï¼š
   - Tiny: å¿«é€Ÿæ¨ç†ï¼Œè¾ƒä½ç²¾åº¦
   - Large: æ›´é«˜ç²¾åº¦ï¼Œè¾ƒæ…¢æ¨ç†
3. **æ‰¹å¤„ç†**: æ‰¹é‡å¤„ç†å¤šä¸ªå›¾åƒ/è§†é¢‘
4. **å†…å­˜ç®¡ç†**: æ¨ç†æ—¶ä½¿ç”¨`torch.inference_mode()`
5. **å›¾åƒä¼˜åŒ–**: å¯¹å¤§å‹å›¾åƒä½¿ç”¨OCRå¤§å°è°ƒæ•´è„šæœ¬

## é€šç”¨åˆ†å‰²è§†é¢‘æ•°æ®é›†

è¯¦æƒ…è¯·å‚è§[sav_dataset/README.md](sav_dataset/README.md)ã€‚

## è®­ç»ƒSAM 2

æ‚¨å¯ä»¥åœ¨å›¾åƒã€è§†é¢‘æˆ–ä¸¤è€…çš„è‡ªå®šä¹‰æ•°æ®é›†ä¸Šè®­ç»ƒæˆ–å¾®è°ƒSAM 2ã€‚è¯·æŸ¥çœ‹è®­ç»ƒ[README](training/README.md)äº†è§£å¦‚ä½•å¼€å§‹ã€‚

## SAM 2çš„Webæ¼”ç¤º

æˆ‘ä»¬å·²å‘å¸ƒSAM 2 Webæ¼”ç¤ºçš„å‰ç«¯+åç«¯ä»£ç ï¼ˆç±»ä¼¼äºhttps://sam2.metademolab.com/demoçš„æœ¬åœ°å¯éƒ¨ç½²ç‰ˆæœ¬ï¼‰ã€‚è¯¦æƒ…è¯·å‚è§Webæ¼”ç¤º[README](demo/README.md)ã€‚

## è®¸å¯è¯

SAM 2æ¨¡å‹æ£€æŸ¥ç‚¹ã€SAM 2æ¼”ç¤ºä»£ç ï¼ˆå‰ç«¯å’Œåç«¯ï¼‰å’ŒSAM 2è®­ç»ƒä»£ç æ ¹æ®[Apache 2.0](./LICENSE)è®¸å¯ï¼Œä½†SAM 2æ¼”ç¤ºä»£ç ä¸­ä½¿ç”¨çš„[Inter Font](https://github.com/rsms/inter?tab=OFL-1.1-1-ov-file)å’Œ[Noto Color Emoji](https://github.com/googlefonts/noto-emoji)æ ¹æ®[SILå¼€æ”¾å­—ä½“è®¸å¯è¯ï¼Œç‰ˆæœ¬1.1](https://openfontlicense.org/open-font-license-official-text/)æä¾›ã€‚

## è´¡çŒ®

è¯·å‚è§[è´¡çŒ®æŒ‡å—](CONTRIBUTING.md)å’Œ[è¡Œä¸ºå‡†åˆ™](CODE_OF_CONDUCT.md)ã€‚

## è´¡çŒ®è€…

SAM 2é¡¹ç›®åœ¨ä¼—å¤šè´¡çŒ®è€…çš„å¸®åŠ©ä¸‹å¾—ä»¥å®ç°ï¼ˆæŒ‰å­—æ¯é¡ºåºï¼‰ï¼š

Karen Bergan, Daniel Bolya, Alex Bosenberg, Kai Brown, Vispi Cassod, Christopher Chedeau, Ida Cheng, Luc Dahlin, Shoubhik Debnath, Rene Martinez Doehner, Grant Gardner, Sahir Gomez, Rishi Godugu, Baishan Guo, Caleb Ho, Andrew Huang, Somya Jain, Bob Kamma, Amanda Kallet, Jake Kinney, Alexander Kirillov, Shiva Koduvayur, Devansh Kukreja, Robert Kuo, Aohan Lin, Parth Malani, Jitendra Malik, Mallika Malhotra, Miguel Martin, Alexander Miller, Sasha Mitts, William Ngan, George Orlin, Joelle Pineau, Kate Saenko, Rodrick Shepard, Azita Shokrpour, David Soofian, Jonathan Torres, Jenny Truong, Sagar Vaze, Meng Wang, Claudette Ward, Pengchuan Zhang.

ç¬¬ä¸‰æ–¹ä»£ç ï¼šæˆ‘ä»¬ä½¿ç”¨ä»[`cc_torch`](https://github.com/zsef123/Connected_components_PyTorch)æ”¹ç¼–çš„åŸºäºGPUçš„è¿é€šåˆ†é‡ç®—æ³•ï¼ˆå…¶è®¸å¯è¯åœ¨[`LICENSE_cctorch`](./LICENSE_cctorch)ä¸­ï¼‰ä½œä¸ºæ©ç é¢„æµ‹çš„å¯é€‰åå¤„ç†æ­¥éª¤ã€‚

## å¼•ç”¨SAM 2

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨SAM 2æˆ–SA-Væ•°æ®é›†ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹BibTeXæ¡ç›®ã€‚

```bibtex
@article{ravi2024sam2,
  title={SAM 2: Segment Anything in Images and Videos},
  author={Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and Mintun, Eric and Pan, Junting and Alwala, Kalyan Vasudev and Carion, Nicolas and Wu, Chao-Yuan and Girshick, Ross and Doll{\'a}r, Piotr and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2408.00714},
  url={https://arxiv.org/abs/2408.00714},
  year={2024}
}
```
